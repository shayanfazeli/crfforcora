{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Familiarity\n",
    "\n",
    "Downloaded the gcn binary features for cora from [this repository](https://github.com/tkipf/gcn/tree/master/gcn/data) into `/data` folder. The following code is taken from the utils and changed to match our project.\n",
    "\n",
    "The adjacency and features matrices are scipy sparse matrices so we do `.A` to convert to numpy ndarrays, which we need for pystruct. Also the adjacency matrix is NxN but we want Nx2 so we get all the indices of nonzero entries and stack the indices in an Nx2 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/tkipf/gcn/blob/master/gcn/utils.py\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "\n",
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "def load_data(dataset_str):\n",
    "    \"\"\"\n",
    "    Loads input data from gcn/data directory\n",
    "    ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
    "        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "    ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict\n",
    "        object;\n",
    "    ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object.\n",
    "    All objects above must be saved using python pickle module.\n",
    "    :param dataset_str: Dataset name\n",
    "    :return: All data input files loaded (as well the training/test data).\n",
    "    \"\"\"\n",
    "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "    labels = np.vstack((ally, ty))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "    idx_test = test_idx_range.tolist()\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "#     y_train[train_mask, :] = labels[train_mask, :]\n",
    "#     y_val[val_mask, :] = labels[val_mask, :]\n",
    "#     y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    y_train = labels[train_mask]\n",
    "    y_val = labels[val_mask]\n",
    "    y_test = labels[test_mask]\n",
    "    # y must be int for pystruct\n",
    "    return adj.A, features.A, y_train.astype(int), y_val.astype(int), y_test.astype(int), train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Not using this anymore.\n",
    "# Combine the indices, shuffle the order, and split again for pystruct\n",
    "pairs = list(zip(adj[0],adj[1]))\n",
    "np.random.shuffle(pairs)\n",
    "shuffled_edges = np.array([[x[0], x[1]] for x in pairs])\n",
    "shuffled_edges = np.array([[x[0] for x in pairs],\n",
    "                           [x[1] for x in pairs]])\n",
    "n_train = features_train.shape[0] - 1\n",
    "n_test = features_test.shape[0] - 1\n",
    "train_edges = shuffled_edges[:,:n_train]\n",
    "test_edges = shuffled_edges[:,n_train:n_train+n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(val1, val2, low, high):\n",
    "    return (low <= val1 <= high) and (low <= val2 <= high)\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(\"cora\")\n",
    "adj = np.vstack(np.nonzero(adj))\n",
    "\n",
    "# print(np.dstack(np.nonzero(adj))[0])\n",
    "# print(adj.shape) # (2708, 2708)\n",
    "# print(features.shape) # (2708, 1433)\n",
    "\n",
    "features_train, features_test = features[train_mask], features[test_mask]\n",
    "nodes_train = np.nonzero(train_mask)[0]\n",
    "nodes_test = np.nonzero(test_mask)[0]\n",
    "\n",
    "\"\"\"\n",
    " Keep edges in training / testing (but ignore edges to nodes outside the set)\n",
    " Also remap the node #, according to the index in nodes_train/test\n",
    " This is because originally we have 2708 nodes, but now for training \n",
    " we  only use  140 nodes. We could pick a node that could have \n",
    " been the 633rd node in the original graph but now it's one of \n",
    " the 140, so the index changes.\n",
    "\"\"\"\n",
    "train_edges = [[], []]\n",
    "test_edges = [[], []]\n",
    "for i in range(adj.shape[1]):\n",
    "    node1 = adj[0][i]\n",
    "    node2 = adj[1][i]\n",
    "    # Check if edge pair is in range\n",
    "    if in_range(node1, node2, nodes_train[0], \n",
    "                nodes_train[len(nodes_train) - 1]):\n",
    "        # This does the index mapping for the adj for the subset graph\n",
    "        index1 = np.where(nodes_train==node1)[0][0]\n",
    "        index2 = np.where(nodes_train==node2)[0][0]\n",
    "        train_edges[0].append(index1)\n",
    "        train_edges[1].append(index2)\n",
    "    # Same thing but now for testing\n",
    "    elif in_range(node1, node2, nodes_test[0], \n",
    "                nodes_test[len(nodes_test) - 1]):\n",
    "        index1 = np.where(nodes_test==node1)[0][0]\n",
    "        index2 = np.where(nodes_test==node2)[0][0]\n",
    "        test_edges[0].append(index1)\n",
    "        test_edges[1].append(index2)\n",
    "        \n",
    "# train_edges = np.vstack([np.arange(features_train.shape[0] - 1), np.arange(1, features_train.shape[0])])\n",
    "# test_edges = np.vstack([np.arange(features_test.shape[0] - 1), np.arange(1, features_test.shape[0])])\n",
    "\n",
    "X_train = [(features_train, np.array(train_edges))]\n",
    "X_test = [(features_test, np.array(test_edges))]\n",
    "\n",
    "# pystruct is expecting it the other way around\n",
    "y_train = y_train.transpose()\n",
    "y_test = y_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "asymmetric, max-product\n",
      "\tScore with pystruct crf subgradient svm: 0.819286 (took 0.078039 seconds)\n",
      "\tScore and time reported by API 0.981000 (0.456822 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf frankwolfe svm: 0.810714 (took 0.028948 seconds)\n",
      "\tScore and time reported by API 0.981571 (0.030324 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf nslack svm: 0.796429 (took 0.192461 seconds)\n",
      "\tScore and time reported by API 0.978714 (3.510830 seconds)\n",
      "**********\n",
      "symmetric, max-product\n",
      "\tScore with pystruct crf subgradient svm: 0.819286 (took 0.048861 seconds)\n",
      "\tScore and time reported by API 0.981000 (0.275885 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf frankwolfe svm: 0.810000 (took 0.030812 seconds)\n",
      "\tScore and time reported by API 0.981429 (0.033145 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf nslack svm: 0.800714 (took 0.169075 seconds)\n",
      "\tScore and time reported by API 0.978429 (2.565343 seconds)\n",
      "**********\n",
      "asymmetric, linear programming\n",
      "\tScore with pystruct crf subgradient svm: 0.802143 (took 0.456568 seconds)\n",
      "\tScore and time reported by API 0.980714 (2.572462 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf frankwolfe svm: 0.810714 (took 0.250076 seconds)\n",
      "\tScore and time reported by API 0.981571 (0.266683 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf nslack svm: 0.797143 (took 1.150856 seconds)\n",
      "\tScore and time reported by API 0.978857 (18.167785 seconds)\n",
      "**********\n",
      "symmetric, linear programming\n",
      "\tScore with pystruct crf subgradient svm: 0.802143 (took 0.491602 seconds)\n",
      "\tScore and time reported by API 0.980714 (2.733553 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf frankwolfe svm: 0.810000 (took 0.252645 seconds)\n",
      "\tScore and time reported by API 0.981429 (0.270129 seconds)\n",
      "\t*****\n",
      "\tScore with pystruct crf nslack svm: 0.800714 (took 0.823755 seconds)\n",
      "\tScore and time reported by API 0.978429 (13.518244 seconds)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from pystruct.models import GraphCRF\n",
    "from pystruct.learners import NSlackSSVM, FrankWolfeSSVM, SubgradientSSVM\n",
    "\n",
    "# Asymmetric pairwise potentials directed=True, linear programming inference\n",
    "asymmetric = GraphCRF(inference_method='max-product', directed=True)\n",
    "symmetric = GraphCRF(inference_method='max-product', directed=False)\n",
    "\n",
    "asymmetriclp = GraphCRF(inference_method='lp', directed=True)\n",
    "symmetriclp = GraphCRF(inference_method='lp', directed=False)\n",
    "\n",
    "models = [(asymmetric, \"asymmetric, max-product\"), (symmetric, \"symmetric, max-product\"),\n",
    "         (asymmetriclp, \"asymmetric, linear programming\"), (symmetriclp, \"symmetric, linear programming\")]\n",
    "for model, modeln in models:\n",
    "    ssvm = SubgradientSSVM(model=model, C=0.1, max_iter=10)\n",
    "    fwsvm = FrankWolfeSSVM(model=model, C=0.1, max_iter=10)\n",
    "    nsvm = NSlackSSVM(model, C=100)\n",
    "    \n",
    "    print(\"*\"*10)\n",
    "    print(modeln)\n",
    "    start = time()\n",
    "    ssvm.fit(X_train, y_train)\n",
    "    time_svm = time() - start\n",
    "    y_pred = np.vstack(ssvm.predict(X_test))\n",
    "    print(\"\\tScore with pystruct crf subgradient svm: %f (took %f seconds)\"\n",
    "          % (np.mean(y_pred == y_test), time_svm))\n",
    "    print(\"\\tScore and time reported by API %f (%f seconds)\"  % (ssvm.score(X_test,y_test), sum(ssvm.timestamps_[1:])))\n",
    "    \n",
    "    print(\"\\t\"+ \"*\"*5)\n",
    "    start = time()\n",
    "    fwsvm.fit(X_train, y_train)\n",
    "    time_svm = time() - start\n",
    "    y_pred = np.vstack(fwsvm.predict(X_test))\n",
    "    print(\"\\tScore with pystruct crf frankwolfe svm: %f (took %f seconds)\"\n",
    "          % (np.mean(y_pred == y_test), time_svm))\n",
    "    print(\"\\tScore and time reported by API %f (%f seconds)\"  % (fwsvm.score(X_test,y_test), sum(fwsvm.timestamps_[1:])))\n",
    "\n",
    "    print(\"\\t\" +\"*\"*5)\n",
    "    start = time()\n",
    "    nsvm.fit(X_train, y_train)\n",
    "    time_svm = time() - start\n",
    "    y_pred = np.vstack(nsvm.predict(X_test))\n",
    "    print(\"\\tScore with pystruct crf nslack svm: %f (took %f seconds)\"\n",
    "          % (np.mean(y_pred == y_test), time_svm))\n",
    "    print(\"\\tScore and time reported by API %f (%f seconds)\"  % (nsvm.score(X_test,y_test), sum(nsvm.timestamps_[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
