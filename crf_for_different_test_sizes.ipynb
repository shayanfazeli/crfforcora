{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import pickle\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./data/restructured_dataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(label):\n",
    "    if label[0] == '/':\n",
    "        return label.split('/')[1]\n",
    "    else:\n",
    "        return label\n",
    "def divide_to_test_and_train(features, labels, test_nodes=None, ids=None):\n",
    "    if test_nodes is None:\n",
    "        last_train_index = 80000\n",
    "        features_train = features[:last_train_index]\n",
    "        labels_train = labels[:last_train_index]\n",
    "        features_test = features[last_train_index:]\n",
    "        labels_test = labels[last_train_index:]\n",
    "    else:\n",
    "        assert(ids is not None)\n",
    "        features_train = []\n",
    "        labels_train = []\n",
    "        features_test = []\n",
    "        labels_test = []\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            if (ids[i][0] in test_nodes) or (ids[i][1] in test_nodes):\n",
    "                features_test.append(features[i])\n",
    "                labels_test.append(labels[i])\n",
    "            else:\n",
    "                features_train.append(features[i])\n",
    "                labels_train.append(labels[i])\n",
    "    return features_train, labels_train, features_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_for_this_number_of_test_nodes(minimum_number_of_test_nodes_wanted):\n",
    "\n",
    "    # another prototype\n",
    "    features = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "\n",
    "    test_nodes = []\n",
    "    treat_as_test_node = False\n",
    "    for citing_id in data['edges'].keys():\n",
    "        cited_ids = data['edges'][citing_id]\n",
    "        if len(test_nodes) < minimum_number_of_test_nodes_wanted:\n",
    "            treat_as_test_node = True\n",
    "        if citing_id in data['features_for_id'].keys() and citing_id in data['label_for_id'].keys():\n",
    "            for i in range(len(cited_ids)):\n",
    "                if cited_ids[i] in data['features_for_id'].keys() and cited_ids[i] in data['label_for_id'].keys():\n",
    "                    ids.append([citing_id, cited_ids[i]])\n",
    "                    the_elements = [\n",
    "                        data['features_for_id'][citing_id], data['features_for_id'][cited_ids[i]]\n",
    "                    ]\n",
    "                    the_labels = [\n",
    "                        process_label(data['label_for_id'][citing_id]), process_label(data['label_for_id'][cited_ids[i]])\n",
    "                    ]\n",
    "                    if not (the_labels[0] == \"NOLABEL\" or the_labels[1] == \"NOLABEL\"):\n",
    "                        features.append(the_elements)\n",
    "                        labels.append(the_labels)\n",
    "                        if treat_as_test_node:\n",
    "                            test_nodes += [citing_id, cited_ids[i]]\n",
    "                            test_nodes = list(set(test_nodes))\n",
    "        treat_as_test_node = False\n",
    "\n",
    "    features_train, labels_train, features_test, labels_test = divide_to_test_and_train(features, labels, test_nodes, ids)\n",
    "\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "    for xseq, yseq in zip(features_train, labels_train):\n",
    "        try:\n",
    "            trainer.append(xseq, yseq)\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "\n",
    "    trainer.set_params({\n",
    "        'c1': 1.0,   # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 50,  # stop earlier\n",
    "\n",
    "        # include transitions that are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "    })\n",
    "\n",
    "\n",
    "    trainer.train('cora%d.crfsuite' % minimum_number_of_test_nodes_wanted)\n",
    "\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open('cora%d.crfsuite' % minimum_number_of_test_nodes_wanted)\n",
    "\n",
    "    from collections import Counter\n",
    "    info = tagger.info()\n",
    "\n",
    "    def print_transitions(trans_features):\n",
    "        for (label_from, label_to), weight in trans_features:\n",
    "            print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "    print(\"Top likely transitions:\")\n",
    "    print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "    print(\"\\nTop unlikely transitions:\")\n",
    "    print_transitions(Counter(info.transitions).most_common()[-15:])\n",
    "\n",
    "    def full_classification_report(y_true, y_pred):\n",
    "        lb = LabelBinarizer()\n",
    "        y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "        y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "\n",
    "        tagset = set(lb.classes_) - {'O'}\n",
    "        tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "        class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "\n",
    "        return classification_report(\n",
    "            y_true_combined,\n",
    "            y_pred_combined,\n",
    "            labels = [class_indices[cls] for cls in tagset],\n",
    "            target_names = tagset,\n",
    "        )\n",
    "\n",
    "\n",
    "    y_pred = [tagger.tag(xseq) for xseq in features_test]\n",
    "\n",
    "    print(full_classification_report(labels_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "Artificial_Intelligence -> Artificial_Intelligence 3.415276\n",
      "Programming -> Programming 3.032480\n",
      "Data_Structures__Algorithms_and_Theory -> Data_Structures__Algorithms_and_Theory 2.791714\n",
      "Human_Computer_Interaction -> Human_Computer_Interaction 2.386109\n",
      "Encryption_and_Compression -> Encryption_and_Compression 2.297515\n",
      "Hardware_and_Architecture -> Hardware_and_Architecture 2.150031\n",
      "Information_Retrieval -> Information_Retrieval 1.930336\n",
      "Networking -> Networking 1.480206\n",
      "Databases -> Databases 1.412418\n",
      "Data_Structures__Algorithms_and_Theory -> Artificial_Intelligence 1.031583\n",
      "Programming -> Data_Structures__Algorithms_and_Theory 0.944250\n",
      "Data_Structures__Algorithms_and_Theory -> Programming 0.838409\n",
      "Artificial_Intelligence -> Data_Structures__Algorithms_and_Theory 0.836973\n",
      "Operating_Systems -> Operating_Systems 0.786721\n",
      "Artificial_Intelligence -> Programming 0.736377\n",
      "\n",
      "Top unlikely transitions:\n",
      "Artificial_Intelligence -> Networking -1.005958\n",
      "Encryption_and_Compression -> Information_Retrieval -1.015495\n",
      "Hardware_and_Architecture -> Human_Computer_Interaction -1.040502\n",
      "Databases -> Encryption_and_Compression -1.182901\n",
      "Information_Retrieval -> Hardware_and_Architecture -1.235223\n",
      "Encryption_and_Compression -> Hardware_and_Architecture -1.253961\n",
      "Encryption_and_Compression -> Databases -1.437057\n",
      "Information_Retrieval -> Data_Structures__Algorithms_and_Theory -1.491640\n",
      "Databases -> Hardware_and_Architecture -1.540536\n",
      "Databases -> Networking -1.605687\n",
      "Hardware_and_Architecture -> Information_Retrieval -1.616530\n",
      "Operating_Systems -> Information_Retrieval -1.701365\n",
      "Networking -> Databases -1.731963\n",
      "Information_Retrieval -> Operating_Systems -1.734594\n",
      "Hardware_and_Architecture -> Encryption_and_Compression -1.775548\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "               Artificial_Intelligence       0.93      0.98      0.96      3941\n",
      "Data_Structures__Algorithms_and_Theory       0.94      0.90      0.92      1010\n",
      "                             Databases       0.96      0.92      0.94       536\n",
      "            Encryption_and_Compression       0.96      0.85      0.90       416\n",
      "             Hardware_and_Architecture       0.95      0.87      0.91       331\n",
      "            Human_Computer_Interaction       0.92      0.84      0.88       506\n",
      "                 Information_Retrieval       0.94      0.87      0.90       200\n",
      "                            Networking       0.92      0.94      0.93       615\n",
      "                     Operating_Systems       0.94      0.95      0.94      1601\n",
      "                           Programming       0.95      0.94      0.94      1688\n",
      "\n",
      "                             micro avg       0.94      0.94      0.94     10844\n",
      "                             macro avg       0.94      0.91      0.92     10844\n",
      "                          weighted avg       0.94      0.94      0.94     10844\n",
      "                           samples avg       0.94      0.94      0.94     10844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_for_this_number_of_test_nodes(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
